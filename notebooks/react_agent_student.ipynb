{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a ReAct Agent from Scratch\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand how LLM API calls work\n",
    "- Implement the ReAct (Reasoning + Acting) framework\n",
    "- Connect an agent to real tools (Grasshopper)\n",
    "\n",
    "**Time:** ~30 minutes follow-along\n",
    "\n",
    "---\n",
    "\n",
    "## Part 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import re      # Regular expressions - used in Part 5 to parse LLM output\n",
    "import json\n",
    "import os\n",
    "\n",
    "# For LLM calls - Groq provides fast inference with generous free tier\n",
    "from groq import Groq\n",
    "\n",
    "# For MCP connection (Grasshopper tools) - httpx handles SSE streaming\n",
    "import httpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure your API key\n",
    "# Get your FREE API key at: https://console.groq.com/keys\n",
    "# Option 1: Set environment variable GROQ_API_KEY\n",
    "# Option 2: Replace the string below\n",
    "\n",
    "API_KEY = os.environ.get(\"GROQ_API_KEY\", \"your-api-key-here\")\n",
    "\n",
    "# Initialize the Groq client\n",
    "client = Groq(api_key=API_KEY)\n",
    "\n",
    "# Quick test - Groq is FAST (100+ tokens/sec!)\n",
    "response = client.chat.completions.create(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Tell me a short haiku about computational design.\"}],\n",
    "    temperature=0.7\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provider Abstraction\n",
    "\n",
    "The function below wraps our LLM calls. To switch providers (OpenAI, Gemini, Anthropic, local models),\n",
    "you only need to change this one function. The rest of the agent code stays the same.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm(messages: list[dict], temperature: float = 0) -> str:\n",
    "    \"\"\"\n",
    "    Call the LLM with a list of messages.\n",
    "\n",
    "    To switch providers, modify this function only.\n",
    "    Currently using: Groq (Llama 3.3 70B)\n",
    "\n",
    "    Args:\n",
    "        messages: List of {\"role\": \"user\"|\"assistant\"|\"system\", \"content\": \"...\"}\n",
    "        temperature: 0 = deterministic, 1 = creative\n",
    "\n",
    "    Returns:\n",
    "        The assistant's response text\n",
    "    \"\"\"\n",
    "    # Groq uses OpenAI-compatible API - messages format works directly!\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama-3.3-70b-versatile\",\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=4096\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: The Agent Class\n",
    "\n",
    "An agent is simply:\n",
    "1. A **system prompt** that defines its behavior\n",
    "2. A **message history** that tracks the conversation\n",
    "3. A **method to call the LLM** and append responses\n",
    "\n",
    "Let's build it from scratch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \"\"\"\n",
    "    A simple conversational agent that maintains message history.\n",
    "\n",
    "    The agent follows whatever behavior is defined in its system prompt.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, system_prompt: str = \"\"):\n",
    "        \"\"\"Initialize the agent with an optional system prompt.\"\"\"\n",
    "        # TODO: Store the system prompt\n",
    "        # TODO: Initialize an empty messages list\n",
    "        # TODO: If system_prompt is provided, add it to messages with role \"system\"\n",
    "        pass\n",
    "\n",
    "    def __call__(self, user_message: str) -> str:\n",
    "        \"\"\"\n",
    "        Send a message to the agent and get a response.\n",
    "\n",
    "        This method:\n",
    "        1. Adds the user message to history\n",
    "        2. Calls the LLM with full history\n",
    "        3. Adds the response to history\n",
    "        4. Returns the response\n",
    "        \"\"\"\n",
    "        # TODO: Append user message to self.messages with role \"user\"\n",
    "        # TODO: Call call_llm(self.messages) to get the response\n",
    "        # TODO: Append the response to self.messages with role \"assistant\"\n",
    "        # TODO: Return the response\n",
    "        pass\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Clear conversation history (keeps system prompt).\"\"\"\n",
    "        # TODO: Reset self.messages to empty list\n",
    "        # TODO: If system_prompt exists, add it back to messages\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test - a simple chatbot\n",
    "test_agent = Agent(\"You are a helpful assistant. Be concise.\")\n",
    "print(test_agent(\"What is 2 + 2?\"))\n",
    "print(test_agent(\"What did I just ask you?\"))  # Tests memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Connecting to Real Tools (Grasshopper MCP)\n",
    "\n",
    "Now we'll connect our agent to **real tools** that can control Grasshopper.\n",
    "\n",
    "The MCP (Model Context Protocol) server exposes these tools:\n",
    "- `list_python_scripts` - Find script components on the canvas\n",
    "- `get_python_script` - Read a script's code\n",
    "- `edit_python_script` - Write/modify code\n",
    "- `get_python_script_errors` - Check for compilation errors\n",
    "\n",
    "**Important:** Make sure Grasshopper is running with the MCP server active!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCP Server Configuration\n",
    "# The Grasshopper MCP uses HTTP + SSE (Server-Sent Events) protocol\n",
    "MCP_URL = \"http://127.0.0.1:8089/mcp\"  # Default endpoint\n",
    "\n",
    "import httpx\n",
    "\n",
    "def call_mcp_tool(tool_name: str, arguments: dict = None) -> dict:\n",
    "    \"\"\"\n",
    "    Call a tool on the Grasshopper MCP server.\n",
    "    \n",
    "    The MCP uses SSE for responses, so we need to stream and parse the events.\n",
    "    \"\"\"\n",
    "    payload = {\n",
    "        \"jsonrpc\": \"2.0\",\n",
    "        \"id\": 1,\n",
    "        \"method\": \"tools/call\",\n",
    "        \"params\": {\n",
    "            \"name\": tool_name,\n",
    "            \"arguments\": arguments or {}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Use httpx with streaming to handle SSE response\n",
    "        with httpx.Client(timeout=30) as client:\n",
    "            with client.stream(\"POST\", MCP_URL, json=payload) as response:\n",
    "                # Read SSE events\n",
    "                for line in response.iter_lines():\n",
    "                    # SSE format: \"data: {json}\"\n",
    "                    if line.startswith(\"data: \"):\n",
    "                        data = json.loads(line[6:])\n",
    "                        # Extract the result from MCP response\n",
    "                        if \"result\" in data:\n",
    "                            return data[\"result\"]\n",
    "                        return data\n",
    "                    elif line.strip() and not line.startswith(\":\"):\n",
    "                        # Try parsing as plain JSON\n",
    "                        try:\n",
    "                            return json.loads(line)\n",
    "                        except:\n",
    "                            pass\n",
    "        return {\"error\": \"No response received\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch available tools from MCP server\n",
    "def get_available_tools() -> list:\n",
    "    \"\"\"Fetch tool definitions from the MCP server.\"\"\"\n",
    "    payload = {\n",
    "        \"jsonrpc\": \"2.0\",\n",
    "        \"id\": 1,\n",
    "        \"method\": \"tools/list\",\n",
    "        \"params\": {}\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        with httpx.Client(timeout=30) as client:\n",
    "            with client.stream(\"POST\", MCP_URL, json=payload) as response:\n",
    "                for line in response.iter_lines():\n",
    "                    if line.startswith(\"data: \"):\n",
    "                        data = json.loads(line[6:])\n",
    "                        if \"result\" in data and \"tools\" in data[\"result\"]:\n",
    "                            return data[\"result\"][\"tools\"]\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching tools: {e}\")\n",
    "        return []\n",
    "\n",
    "# Get tools and filter to the ones we want for this tutorial\n",
    "ALL_TOOLS = get_available_tools()\n",
    "\n",
    "# For this tutorial, we focus on Python script tools\n",
    "TUTORIAL_TOOLS = [t for t in ALL_TOOLS if t[\"name\"] in [\n",
    "    \"List_Python_Scripts\",\n",
    "    \"Get_Python_Script\", \n",
    "    \"Edit_Python_Script\",\n",
    "    \"Get_Python_Script_Errors\"\n",
    "]]\n",
    "\n",
    "print(f\"Found {len(ALL_TOOLS)} total tools, using {len(TUTORIAL_TOOLS)} for this tutorial:\")\n",
    "for tool in TUTORIAL_TOOLS:\n",
    "    print(f\"  - {tool['name']}: {tool['description'][:60]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Call a tool directly\n",
    "result = call_mcp_tool(\"List_Python_Scripts\")\n",
    "print(\"Python scripts on canvas:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: The ReAct Framework\n",
    "\n",
    "**ReAct** = **Re**asoning + **Act**ing\n",
    "\n",
    "The key insight: LLMs can follow a structured loop if we tell them to:\n",
    "\n",
    "1. **Thought** - Reason about what to do next\n",
    "2. **Action** - Call a tool with specific input\n",
    "3. **PAUSE** - Stop and wait for the tool result\n",
    "4. **Observation** - Receive the tool's output\n",
    "5. **Repeat** until ready to give final **Answer**\n",
    "\n",
    "The magic is in the **prompt**. Let's build it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ReAct prompt with Anthropic best practices + Grasshopper context\n",
    "\n",
    "def build_react_prompt(tools: list) -> str:\n",
    "    \"\"\"Build a ReAct prompt from MCP tool definitions.\"\"\"\n",
    "    \n",
    "    # Format tools as simple list\n",
    "    tool_docs = []\n",
    "    for tool in tools:\n",
    "        name = tool[\"name\"]\n",
    "        desc = tool[\"description\"].split('.')[0]  # First sentence only\n",
    "        params = tool.get(\"inputSchema\", {}).get(\"properties\", {})\n",
    "        param_names = list(params.keys())\n",
    "        tool_docs.append(f\"- {name}: {desc}. Parameters: {param_names if param_names else 'none'}\")\n",
    "    \n",
    "    tools_section = \"\\n\".join(tool_docs)\n",
    "    \n",
    "    return f\"\"\"You are a Grasshopper Python scripting assistant that creates geometry.\n",
    "\n",
    "<context>\n",
    "You write Python scripts for Grasshopper (Rhino's visual programming tool).\n",
    "Scripts run inside a Python component with predefined output variables.\n",
    "</context>\n",
    "\n",
    "<grasshopper_rules>\n",
    "- Output geometry by assigning to variable 'a': a = my_points\n",
    "- Import Rhino.Geometry as rg for geometry types\n",
    "- Use rg.Point3d(x,y,z) for points, rg.Line() for lines, etc.\n",
    "- Lists of geometry display as multiple objects\n",
    "- Always assign final result to 'a' or it won't display!\n",
    "</grasshopper_rules>\n",
    "\n",
    "<tools>\n",
    "{tools_section}\n",
    "</tools>\n",
    "\n",
    "<workflow>\n",
    "1. Thought: reason about what to do\n",
    "2. Action: call a tool, then PAUSE\n",
    "3. Wait for Observation\n",
    "4. After editing code, always check for errors\n",
    "5. Only give Answer when code works\n",
    "</workflow>\n",
    "\n",
    "<format>\n",
    "Action: ToolName {{\"param\": \"value\"}}\n",
    "</format>\n",
    "\n",
    "<example>\n",
    "User: Create a spiral of 10 points\n",
    "\n",
    "Thought: Find the script component first.\n",
    "Action: List_Python_Scripts\n",
    "PAUSE\n",
    "\n",
    "Observation: [{{\"id\": \"abc-123\", \"name\": \"Task\"}}]\n",
    "\n",
    "Thought: Write code for a spiral. Must assign to 'a' for output.\n",
    "Action: Edit_Python_Script {{\"componentId\": \"abc-123\", \"code\": \"import Rhino.Geometry as rg\\\\nimport math\\\\n\\\\npoints = []\\\\nfor i in range(10):\\\\n    angle = i * 0.5\\\\n    x = math.cos(angle) * i\\\\n    y = math.sin(angle) * i\\\\n    points.append(rg.Point3d(x, y, 0))\\\\n\\\\na = points\"}}\n",
    "PAUSE\n",
    "\n",
    "Observation: Script updated\n",
    "\n",
    "Thought: Check for errors.\n",
    "Action: Get_Python_Script_Errors {{\"componentId\": \"abc-123\"}}\n",
    "PAUSE\n",
    "\n",
    "Observation: No errors\n",
    "\n",
    "Answer: Created spiral of 10 points, assigned to output 'a'.\n",
    "</example>\n",
    "\"\"\"\n",
    "\n",
    "REACT_PROMPT = build_react_prompt(TUTORIAL_TOOLS)\n",
    "print(f\"Prompt built ({len(REACT_PROMPT)} chars)\")\n",
    "print(REACT_PROMPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why This Prompt Works\n",
    "\n",
    "Notice the key elements:\n",
    "1. **Role definition** - \"You are a Grasshopper scripting assistant\"\n",
    "2. **Loop structure** - Explicit Thought -> Action -> PAUSE -> Observation cycle\n",
    "3. **Tool descriptions** - Exact syntax with examples\n",
    "4. **Workflow rules** - \"ALWAYS check for errors\"\n",
    "5. **Example session** - Shows the expected format\n",
    "\n",
    "The LLM follows this because it's trained to follow instructions.\n",
    "The more specific and structured your prompt, the more reliable the behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: The ReAct Execution Loop\n",
    "\n",
    "Now we need code that:\n",
    "1. Parses the LLM's output to find Actions\n",
    "2. Executes the corresponding tool\n",
    "3. Feeds the result back as an Observation\n",
    "4. Repeats until we get an Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse actions from LLM response\n",
    "# Format: \"Action: ToolName\" or \"Action: ToolName {\"param\": \"value\"}\"\n",
    "ACTION_PATTERN = re.compile(r'^Action:\\s*(\\w+)\\s*(\\{.*\\})?$', re.MULTILINE)\n",
    "\n",
    "def parse_action(response: str) -> tuple[str, dict] | None:\n",
    "    \"\"\"\n",
    "    Parse an action from the LLM response.\n",
    "    \n",
    "    Expected format in response:\n",
    "        Action: ToolName {\"param\": \"value\"}\n",
    "    \n",
    "    Returns: (tool_name, arguments_dict) or None if no action found\n",
    "    \"\"\"\n",
    "    # TODO: Use ACTION_PATTERN.search(response) to find an action\n",
    "    # TODO: If match found:\n",
    "    #   - Extract tool_name from match.group(1)\n",
    "    #   - Extract args_str from match.group(2) (may be None)\n",
    "    #   - If args_str exists, parse it with json.loads()\n",
    "    #   - Return (tool_name, args)\n",
    "    # TODO: If no match, return None\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute tool actions via MCP\n",
    "def execute_action(tool_name: str, args: dict) -> str:\n",
    "    \"\"\"\n",
    "    Execute a tool and return the result as a string.\n",
    "    \n",
    "    Args:\n",
    "        tool_name: Name of the MCP tool to call\n",
    "        args: Dictionary of arguments for the tool\n",
    "    \n",
    "    Returns:\n",
    "        String representation of the result (for feeding back to LLM)\n",
    "    \"\"\"\n",
    "    # TODO: Call call_mcp_tool(tool_name, args) to get result\n",
    "    # TODO: Format the result as a string:\n",
    "    #   - If result is a dict with \"error\" key, return f\"Error: {result['error']}\"\n",
    "    #   - If result is a dict or list, return json.dumps(result, indent=2)\n",
    "    #   - Otherwise return str(result)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ReAct execution loop\n",
    "def query(question: str, max_turns: int = 10, verbose: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    Run the ReAct loop to answer a question.\n",
    "    \n",
    "    The loop:\n",
    "    1. Send question/observation to agent\n",
    "    2. Check if response contains \"Answer:\" (without PAUSE) -> return it\n",
    "    3. Parse action from response\n",
    "    4. Execute action and get observation\n",
    "    5. Feed observation back and repeat\n",
    "    \n",
    "    Args:\n",
    "        question: The user's question/request\n",
    "        max_turns: Maximum number of reasoning turns\n",
    "        verbose: Whether to print each turn\n",
    "    \n",
    "    Returns:\n",
    "        The final answer from the agent\n",
    "    \"\"\"\n",
    "    # TODO: Create an Agent with REACT_PROMPT\n",
    "    # TODO: Set next_prompt = question\n",
    "    # TODO: Loop for max_turns:\n",
    "    #   - Call agent(next_prompt) to get response\n",
    "    #   - If verbose, print the turn number and response\n",
    "    #   - Check if \"Answer:\" in response AND \"PAUSE\" not in response\n",
    "    #       -> If so, extract and return the answer\n",
    "    #   - Call parse_action(response) to get action\n",
    "    #   - If action found:\n",
    "    #       -> Execute it with execute_action()\n",
    "    #       -> Set next_prompt = f\"Observation: {observation}\"\n",
    "    #   - If no action found:\n",
    "    #       -> Set next_prompt = \"Continue with an Action or provide your Answer.\"\n",
    "    # TODO: Return \"Max turns reached.\" if loop exhausts\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Let's Run It!\n",
    "\n",
    "Now for the exciting part. Let's ask our agent to create geometry in Grasshopper.\n",
    "\n",
    "**Make sure:**\n",
    "1. Grasshopper is open\n",
    "2. You have a Python 3 Script component on the canvas\n",
    "3. The MCP server is running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE MAIN EVENT\n",
    "# Change this prompt to create different geometry!\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "Create a spiral staircase including steps\n",
    "\"\"\"\n",
    "\n",
    "result = query(user_prompt)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL ANSWER:\")\n",
    "print(\"=\"*50)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## What You Learned\n",
    "\n",
    "1. **LLM API calls** are just HTTP requests with message history\n",
    "2. **ReAct framework** = Thought + Action + Observation loop\n",
    "3. **The prompt is everything** - structured instructions create structured behavior\n",
    "4. **Tools extend capabilities** - connect LLMs to real systems via MCP\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Read the original ReAct paper: Yao et al., 2022\n",
    "- Explore the Grasshopper MCP documentation\n",
    "- Try connecting other tools (web search, file system, etc.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
